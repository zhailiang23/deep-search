---
id: 002
title: 双模式向量处理引擎
epic: 创建智能搜索平台
status: pending
priority: high
assignee: ""
labels: ["向量化", "AI集成", "模式切换"]
created: 2025-09-20T02:23:58Z
updated: 2025-09-20T04:52:50Z
estimate: L
parallel: false
dependencies: ["001"]
---

# 双模式向量处理引擎

## 描述

构建智能搜索平台的核心向量处理引擎，支持离线批量处理和在线实时处理两种模式。集成多种向量化API（OpenAI、本地模型等），实现智能的模式切换机制，为文档和查询提供高质量的向量表示。

## 验收标准

- [ ] 离线批量向量化处理，支持大文件和批量文档
- [ ] 在线实时向量化，查询响应时间<2秒
- [ ] 支持多种向量化模型（OpenAI text-embedding-3-small/large, 本地BERT等）
- [ ] 智能模式切换：根据负载、成本、响应时间自动选择处理模式
- [ ] 向量缓存机制，避免重复计算
- [ ] 向量质量评估和监控
- [ ] 异步任务队列，支持大规模文档处理
- [ ] 向量处理失败重试和错误恢复机制
- [ ] 性能监控和指标收集

## 技术细节

### 核心组件架构

```java
// 向量处理引擎接口
public interface VectorProcessingEngine {
    CompletableFuture<Vector> processDocument(Document document, ProcessingMode mode);
    CompletableFuture<Vector> processQuery(String query, ProcessingMode mode);
    void switchMode(ProcessingMode mode);
    ProcessingMetrics getMetrics();
}

// 处理模式枚举
public enum ProcessingMode {
    OFFLINE_BATCH,    // 离线批量处理
    ONLINE_REALTIME,  // 在线实时处理
    AUTO_SWITCH       // 自动切换
}
```

### 向量化服务提供商

**OpenAI集成**
```java
@Service
public class OpenAIVectorService implements VectorService {
    private final OpenAIClient client;

    @Override
    public Vector generateEmbedding(String text, String model) {
        // text-embedding-3-small: 1536维, 成本低
        // text-embedding-3-large: 3072维, 质量高
    }
}
```

**本地模型集成**
```java
@Service
public class LocalBertVectorService implements VectorService {
    private final SentenceTransformer model;

    @Override
    public Vector generateEmbedding(String text, String model) {
        // 本地BERT模型, 无外部依赖
    }
}
```

### 智能模式切换策略

```java
@Component
public class ModeSwithcStrategy {

    @Autowired
    private SystemMetrics systemMetrics;

    public ProcessingMode determineOptimalMode(ProcessingContext context) {
        // 决策因子：
        // 1. 当前系统负载
        // 2. 队列长度
        // 3. 成本预算
        // 4. 响应时间要求
        // 5. 模型可用性
    }
}
```

### 数据库扩展

```sql
-- 向量表
CREATE TABLE document_vectors (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    document_id BIGINT NOT NULL,
    vector_data JSON NOT NULL,  -- 存储向量数组
    model_name VARCHAR(100) NOT NULL,
    model_version VARCHAR(50),
    vector_dimension INT NOT NULL,
    processing_mode ENUM('OFFLINE', 'ONLINE') NOT NULL,
    processing_time_ms INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (document_id) REFERENCES documents(id),
    INDEX idx_document_model (document_id, model_name)
);

-- 向量处理任务队列
CREATE TABLE vector_processing_tasks (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    document_id BIGINT NOT NULL,
    task_type ENUM('INITIAL', 'REPROCESS', 'QUALITY_CHECK') NOT NULL,
    priority INT DEFAULT 5,
    status ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED') DEFAULT 'PENDING',
    retry_count INT DEFAULT 0,
    max_retries INT DEFAULT 3,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL,
    FOREIGN KEY (document_id) REFERENCES documents(id),
    INDEX idx_status_priority (status, priority, created_at)
);

-- 向量处理指标
CREATE TABLE vector_processing_metrics (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    date_hour DATETIME NOT NULL,  -- 按小时聚合
    processing_mode ENUM('OFFLINE', 'ONLINE') NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    total_requests INT DEFAULT 0,
    successful_requests INT DEFAULT 0,
    failed_requests INT DEFAULT 0,
    avg_processing_time_ms INT,
    total_cost_cents INT DEFAULT 0,  -- 以分为单位存储成本
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY uk_metrics (date_hour, processing_mode, model_name)
);
```

### 配置管理

**application.yml扩展**
```yaml
vector-processing:
  default-mode: AUTO_SWITCH

  openai:
    api-key: ${OPENAI_API_KEY}
    models:
      small: text-embedding-3-small
      large: text-embedding-3-large
    rate-limit: 1000  # requests per minute

  local-models:
    bert:
      model-path: ./models/sentence-transformer
      max-sequence-length: 512

  cache:
    enabled: true
    ttl: 24h
    max-size: 10000

  mode-switching:
    auto-switch-enabled: true
    cost-threshold-cents: 1000  # 每小时成本阈值
    latency-threshold-ms: 3000  # 延迟阈值
    queue-size-threshold: 100   # 队列长度阈值

  task-queue:
    batch-size: 50
    max-concurrent-tasks: 10
    retry-delay-seconds: 60
```

### 核心服务实现

```java
@Service
@Slf4j
public class VectorProcessingEngineImpl implements VectorProcessingEngine {

    @Autowired
    private List<VectorService> vectorServices;

    @Autowired
    private VectorCache vectorCache;

    @Autowired
    private TaskQueueService taskQueueService;

    @Autowired
    private ModeSwithcStrategy modeStrategy;

    @Override
    public CompletableFuture<Vector> processDocument(Document document, ProcessingMode mode) {
        // 1. 检查缓存
        // 2. 选择向量化服务
        // 3. 文本预处理和分块
        // 4. 向量化处理
        // 5. 质量验证
        // 6. 缓存和持久化
    }

    @Override
    public CompletableFuture<Vector> processQuery(String query, ProcessingMode mode) {
        // 查询向量化，优先使用在线模式
    }
}
```

## 依赖关系

**前置依赖**:
- 001: Spring Boot平台搭建 (需要基础框架和数据库)

**后续任务依赖此任务**:
- 003: Elasticsearch搜索引擎集成

## 工作量估算

**规模**: L (大型)
**预估时间**: 2-3周
**并行性**: false (关键路径)

### 分解任务
1. 向量服务接口设计和OpenAI集成 (4天)
2. 本地模型集成和服务抽象 (3天)
3. 双模式处理引擎核心逻辑 (4天)
4. 智能模式切换策略实现 (3天)
5. 异步任务队列和批处理 (3天)
6. 向量缓存和性能优化 (2天)
7. 监控指标和错误处理 (2天)
8. 单元测试和集成测试 (3天)

## 完成定义

任务完成需满足以下条件：
1. 所有验收标准项目通过
2. 离线模式处理1000个文档的吞吐量测试通过
3. 在线模式并发50查询的性能测试通过
4. 模式切换逻辑在不同负载下正常工作
5. 向量质量评估达到基准指标
6. 错误恢复和重试机制验证通过

## 风险与缓解

**技术风险**:
- OpenAI API限流和成本控制 → 实现智能重试和成本监控
- 本地模型内存占用过高 → 模型量化和资源管理
- 向量维度不匹配 → 标准化向量接口和验证

**业务风险**:
- 向量化成本超预算 → 实时成本监控和预警
- 处理延迟影响用户体验 → 缓存策略和预处理
