---
id: 004
title: 智能搜索功能实现
epic: 创建智能搜索平台
status: closed
priority: high
assignee: ""
labels: ["搜索算法", "语义搜索", "自动补全", "相关度排序"]
created: 2025-09-20T02:23:58Z
updated: 2025-09-20T12:11:21Z
estimate: L
parallel: false
dependencies: [003]
---

# 智能搜索功能实现

## 描述

实现智能搜索平台的核心搜索功能，包括语义搜索算法、相关度排序、搜索建议和自动补全。基于Elasticsearch和向量数据库，提供高性能的混合搜索能力，支持同义词匹配、场景关联和智能推荐。

## 验收标准

- [ ] 语义搜索响应时间 < 200ms (95百分位)
- [ ] 关键词搜索响应时间 < 100ms (95百分位)
- [ ] 混合搜索准确率 > 85% (基于测试数据集)
- [ ] 自动补全响应时间 < 50ms
- [ ] 搜索建议命中率 > 70%
- [ ] 同义词匹配覆盖率 > 80% (常用词汇)
- [ ] 支持并发1000用户同时搜索
- [ ] 搜索结果相关度评分准确性 > 90%
- [ ] 缓存命中率 > 60%
- [ ] 搜索无结果率 < 15%

## 技术细节

### 核心搜索算法

**混合搜索引擎**
```java
@Service
public class HybridSearchService {

    @Autowired
    private ElasticsearchService elasticsearchService;

    @Autowired
    private VectorSearchService vectorSearchService;

    @Autowired
    private SearchRelevanceService relevanceService;

    public SearchResult hybridSearch(SearchRequest request) {
        // 1. 并行执行关键词和语义搜索
        CompletableFuture<List<Document>> keywordResults =
            CompletableFuture.supplyAsync(() ->
                elasticsearchService.keywordSearch(request));

        CompletableFuture<List<Document>> semanticResults =
            CompletableFuture.supplyAsync(() ->
                vectorSearchService.semanticSearch(request));

        // 2. 合并和重排序结果
        List<Document> mergedResults = relevanceService.mergeAndRank(
            keywordResults.join(),
            semanticResults.join(),
            request.getWeights()
        );

        // 3. 应用业务规则和个性化
        return applyBusinessRules(mergedResults, request);
    }
}
```

**语义搜索实现**
```java
@Service
public class SemanticSearchService {

    @Autowired
    private VectorService vectorService;

    @Autowired
    private SynonymService synonymService;

    @Autowired
    private ContextService contextService;

    public List<Document> semanticSearch(String query, SearchContext context) {
        // 1. 查询向量化
        float[] queryVector = vectorService.encode(query);

        // 2. 同义词扩展
        List<String> expandedQueries = synonymService.expandQuery(query);

        // 3. 场景关联查询
        SceneContext sceneContext = contextService.inferScene(query, context);

        // 4. 向量相似度搜索
        List<VectorResult> vectorResults = vectorService.similaritySearch(
            queryVector,
            sceneContext.getFilters(),
            100 // topK
        );

        // 5. 语义重排序
        return semanticRanking(vectorResults, expandedQueries, sceneContext);
    }
}
```

### 相关度排序算法

**多维度评分模型**
```java
@Component
public class RelevanceScorer {

    private static final float KEYWORD_WEIGHT = 0.4f;
    private static final float SEMANTIC_WEIGHT = 0.3f;
    private static final float FRESHNESS_WEIGHT = 0.1f;
    private static final float POPULARITY_WEIGHT = 0.1f;
    private static final float PERSONALIZATION_WEIGHT = 0.1f;

    public float calculateRelevanceScore(Document doc, SearchRequest request) {
        float keywordScore = calculateKeywordScore(doc, request.getQuery());
        float semanticScore = calculateSemanticScore(doc, request.getQueryVector());
        float freshnessScore = calculateFreshnessScore(doc.getCreatedAt());
        float popularityScore = calculatePopularityScore(doc.getViewCount(), doc.getLikeCount());
        float personalizationScore = calculatePersonalizationScore(doc, request.getUserContext());

        return keywordScore * KEYWORD_WEIGHT +
               semanticScore * SEMANTIC_WEIGHT +
               freshnessScore * FRESHNESS_WEIGHT +
               popularityScore * POPULARITY_WEIGHT +
               personalizationScore * PERSONALIZATION_WEIGHT;
    }

    private float calculateKeywordScore(Document doc, String query) {
        // TF-IDF + BM25算法
        float tfIdfScore = calculateTfIdf(doc.getContent(), query);
        float bm25Score = calculateBM25(doc.getContent(), query);
        return Math.max(tfIdfScore, bm25Score);
    }

    private float calculateSemanticScore(Document doc, float[] queryVector) {
        // 余弦相似度计算
        float[] docVector = doc.getVector();
        return cosineSimilarity(queryVector, docVector);
    }
}
```

### 同义词匹配系统

**智能同义词引擎**
```java
@Service
public class SynonymService {

    @Autowired
    private SynonymRepository synonymRepository;

    @Autowired
    private NLPService nlpService;

    private final Cache<String, List<String>> synonymCache =
        Caffeine.newBuilder()
            .maximumSize(10000)
            .expireAfterWrite(1, TimeUnit.HOURS)
            .build();

    public List<String> expandQuery(String query) {
        // 1. 分词和词性标注
        List<Token> tokens = nlpService.tokenize(query);

        // 2. 提取关键词
        List<String> keywords = extractKeywords(tokens);

        // 3. 同义词扩展
        Set<String> expandedTerms = new HashSet<>();
        expandedTerms.add(query); // 原查询

        for (String keyword : keywords) {
            List<String> synonyms = getSynonyms(keyword);
            expandedTerms.addAll(synonyms);
        }

        // 4. 语义相似词扩展
        List<String> semanticSimilar = nlpService.findSimilarTerms(query, 5);
        expandedTerms.addAll(semanticSimilar);

        return new ArrayList<>(expandedTerms);
    }

    private List<String> getSynonyms(String term) {
        return synonymCache.get(term, key -> {
            // 静态同义词词典
            List<String> staticSynonyms = synonymRepository.findByTerm(key);

            // 动态同义词发现
            List<String> dynamicSynonyms = nlpService.findDynamicSynonyms(key);

            Set<String> allSynonyms = new HashSet<>();
            allSynonyms.addAll(staticSynonyms);
            allSynonyms.addAll(dynamicSynonyms);

            return new ArrayList<>(allSynonyms);
        });
    }
}
```

### 场景关联功能

**上下文感知搜索**
```java
@Service
public class ContextAwareSearchService {

    @Autowired
    private UserBehaviorService userBehaviorService;

    @Autowired
    private SceneClassifier sceneClassifier;

    public SearchContext buildSearchContext(String query, User user, HttpServletRequest request) {
        SearchContext context = new SearchContext();

        // 1. 用户行为分析
        UserProfile profile = userBehaviorService.getUserProfile(user.getId());
        context.setUserPreferences(profile.getPreferences());
        context.setSearchHistory(profile.getRecentSearches());

        // 2. 场景识别
        SearchScene scene = sceneClassifier.classifyScene(query, profile);
        context.setScene(scene);

        // 3. 时间上下文
        TimeContext timeContext = buildTimeContext();
        context.setTimeContext(timeContext);

        // 4. 地理位置上下文
        if (request.getHeader("X-User-Location") != null) {
            LocationContext locationContext = parseLocation(request.getHeader("X-User-Location"));
            context.setLocationContext(locationContext);
        }

        return context;
    }

    public List<Document> applyContextualFilters(List<Document> results, SearchContext context) {
        return results.stream()
            .filter(doc -> isRelevantToScene(doc, context.getScene()))
            .filter(doc -> matchesUserPreferences(doc, context.getUserPreferences()))
            .filter(doc -> isTimerelevant(doc, context.getTimeContext()))
            .collect(Collectors.toList());
    }
}
```

### 自动补全系统

**智能自动补全**
```java
@RestController
@RequestMapping("/api/search")
public class AutoCompleteController {

    @Autowired
    private AutoCompleteService autoCompleteService;

    @GetMapping("/autocomplete")
    public ResponseEntity<List<Suggestion>> autocomplete(
            @RequestParam String query,
            @RequestParam(defaultValue = "10") int limit,
            HttpServletRequest request) {

        User user = getCurrentUser(request);
        List<Suggestion> suggestions = autoCompleteService.getSuggestions(query, user, limit);

        return ResponseEntity.ok(suggestions);
    }
}

@Service
public class AutoCompleteService {

    @Autowired
    private TrieService trieService;

    @Autowired
    private PopularityService popularityService;

    @Autowired
    private PersonalizationService personalizationService;

    private final Cache<String, List<Suggestion>> suggestionCache =
        Caffeine.newBuilder()
            .maximumSize(50000)
            .expireAfterWrite(30, TimeUnit.MINUTES)
            .build();

    public List<Suggestion> getSuggestions(String query, User user, int limit) {
        String cacheKey = buildCacheKey(query, user.getId());

        return suggestionCache.get(cacheKey, key -> {
            // 1. Trie树前缀匹配
            List<String> trieMatches = trieService.getPrefixMatches(query, limit * 2);

            // 2. 热门搜索建议
            List<String> popularSuggestions = popularityService.getPopularQueries(query, limit);

            // 3. 个性化建议
            List<String> personalizedSuggestions =
                personalizationService.getPersonalizedSuggestions(query, user, limit);

            // 4. 合并和排序
            return mergeSuggestions(trieMatches, popularSuggestions, personalizedSuggestions, limit);
        });
    }

    private List<Suggestion> mergeSuggestions(List<String> trie, List<String> popular,
                                            List<String> personalized, int limit) {
        Map<String, Suggestion> suggestionMap = new LinkedHashMap<>();

        // 个性化建议优先级最高
        personalized.forEach(s -> suggestionMap.put(s,
            new Suggestion(s, SuggestionType.PERSONALIZED, 1.0f)));

        // 热门建议次之
        popular.forEach(s -> suggestionMap.putIfAbsent(s,
            new Suggestion(s, SuggestionType.POPULAR, 0.8f)));

        // Trie匹配最低
        trie.forEach(s -> suggestionMap.putIfAbsent(s,
            new Suggestion(s, SuggestionType.PREFIX_MATCH, 0.6f)));

        return suggestionMap.values().stream()
            .sorted((a, b) -> Float.compare(b.getScore(), a.getScore()))
            .limit(limit)
            .collect(Collectors.toList());
    }
}
```

### 搜索建议系统

**智能搜索建议**
```java
@Service
public class SearchSuggestionService {

    @Autowired
    private QueryAnalysisService queryAnalysisService;

    @Autowired
    private RecommendationEngine recommendationEngine;

    public SearchSuggestionResponse generateSuggestions(String query, SearchResult currentResult) {
        SearchSuggestionResponse response = new SearchSuggestionResponse();

        // 1. 查询意图分析
        QueryIntent intent = queryAnalysisService.analyzeIntent(query);

        // 2. 生成改进建议
        if (currentResult.getTotalCount() < 5) {
            // 结果太少，建议扩展查询
            List<String> expansionSuggestions = generateExpansionSuggestions(query, intent);
            response.setExpansionSuggestions(expansionSuggestions);
        }

        if (currentResult.getTotalCount() > 1000) {
            // 结果太多，建议缩小范围
            List<String> narrowingSuggestions = generateNarrowingSuggestions(query, intent);
            response.setNarrowingSuggestions(narrowingSuggestions);
        }

        // 3. 相关搜索建议
        List<String> relatedQueries = recommendationEngine.getRelatedQueries(query, 5);
        response.setRelatedQueries(relatedQueries);

        // 4. 拼写纠错建议
        if (currentResult.getTotalCount() == 0) {
            List<String> spellingSuggestions = generateSpellingSuggestions(query);
            response.setSpellingSuggestions(spellingSuggestions);
        }

        return response;
    }
}
```

### 性能优化

**缓存策略**
```java
@Configuration
@EnableCaching
public class SearchCacheConfig {

    @Bean
    public CacheManager searchCacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(10000)
            .expireAfterWrite(15, TimeUnit.MINUTES)
            .recordStats());
        return cacheManager;
    }

    @Bean
    public RedisTemplate<String, Object> searchRedisTemplate() {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(redisConnectionFactory());
        template.setDefaultSerializer(new GenericJackson2JsonRedisSerializer());
        return template;
    }
}

@Service
public class SearchCacheService {

    @Cacheable(value = "searchResults", key = "#query + '_' + #filters.hashCode()")
    public SearchResult getCachedSearchResult(String query, SearchFilters filters) {
        // 缓存搜索结果
        return null; // 由AOP处理缓存逻辑
    }

    @Cacheable(value = "autoComplete", key = "#prefix + '_' + #userId")
    public List<Suggestion> getCachedSuggestions(String prefix, Long userId) {
        // 缓存自动补全结果
        return null;
    }
}
```

## 数据库设计

```sql
-- 同义词表
CREATE TABLE synonyms (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    term VARCHAR(100) NOT NULL,
    synonym VARCHAR(100) NOT NULL,
    confidence FLOAT DEFAULT 1.0,
    source ENUM('MANUAL', 'AUTO', 'ML') DEFAULT 'MANUAL',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_term (term),
    INDEX idx_synonym (synonym)
);

-- 搜索统计表
CREATE TABLE search_analytics (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    query_text VARCHAR(1000) NOT NULL,
    result_count INT DEFAULT 0,
    click_count INT DEFAULT 0,
    avg_position FLOAT,
    bounce_rate FLOAT,
    search_date DATE NOT NULL,
    INDEX idx_query_date (query_text, search_date),
    INDEX idx_search_date (search_date)
);

-- 用户搜索偏好表
CREATE TABLE user_search_preferences (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    preferred_categories JSON,
    search_history JSON,
    click_patterns JSON,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    INDEX idx_user_id (user_id)
);

-- 搜索建议表
CREATE TABLE search_suggestions (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    query VARCHAR(500) NOT NULL,
    suggestion VARCHAR(500) NOT NULL,
    suggestion_type ENUM('EXPANSION', 'NARROWING', 'CORRECTION', 'RELATED'),
    confidence FLOAT DEFAULT 1.0,
    usage_count INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_query (query),
    INDEX idx_type_confidence (suggestion_type, confidence)
);
```

## 依赖关系

**前置依赖**:
- 003: Elasticsearch搜索引擎集成

**后续任务依赖此任务**:
- 005: 三层权限管理系统 (搜索权限控制)
- 006: JSON数据管理系统 (搜索内容管理)

## 工作量估算

**规模**: L (大型)
**预估时间**: 3-4周
**并行性**: false (依赖搜索引擎)

### 分解任务
1. 混合搜索算法设计和实现 (5天)
2. 语义搜索和向量相似度计算 (4天)
3. 同义词匹配和查询扩展 (3天)
4. 相关度排序算法优化 (4天)
5. 自动补全和搜索建议 (3天)
6. 场景关联和上下文感知 (3天)
7. 性能优化和缓存策略 (3天)
8. 搜索分析和监控 (2天)
9. 单元测试和集成测试 (3天)

## 完成定义

任务完成需满足以下条件：
1. 所有验收标准的性能指标达标
2. 搜索准确率通过A/B测试验证
3. 并发压力测试通过1000用户
4. 代码覆盖率达到85%以上
5. 搜索响应时间满足SLA要求
6. 缓存命中率达到目标值

## 风险与缓解

**技术风险**:
- 向量搜索性能瓶颈 → 使用FAISS优化，实施分片策略
- 同义词质量问题 → 建立人工审核机制，持续优化词典
- 相关度算法准确性 → 基于用户行为数据调优权重

**业务风险**:
- 搜索结果质量不满足预期 → 建立评估指标体系，定期优化
- 个性化推荐冷启动问题 → 设计默认推荐策略

**性能风险**:
- 高并发下响应延迟 → 多级缓存，异步处理，负载均衡
- 内存消耗过大 → 优化向量存储，使用内存映射文件